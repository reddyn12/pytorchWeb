# GOALS

Goal is to use Pytorch, Flask and ONNX to run a model on browser using the clients resources

Going to adapt https://github.com/jobergum/browser-ml-inference to work for this... The clone works staight out of box, so shouldn't be hard to convert

Going to test it on huggingface gpt and then work backwards from there


